# PySpark Practice Repository

This repository contains basic PySpark programs created for learning and practice.

## Files and Descriptions

• caching.py – Examples of caching and persisting in Spark.

• configuration.py – Setup for SparkSession, SparkContext, and basic operations.

• genral_df.py – General DataFrame operations and string functions.

• git/ – Folder related to Git configuration (if any).

• normal.py – Older version of caching and Spark SQL examples.

• numeric_function.py – Demonstrates numeric functions like SUM, AVG, MAX, etc.

• operations.py – Basic transformations and actions in PySpark.

• persist.py – Persistence examples using Spark SQL.

• pysaprk_dataframe.py – DataFrame creation and manipulation.

• spark_sql.py – Running SQL queries using Spark SQL.

• string functions.py – Working with string functions in PySpark.

• aggregation.py – Aggregation functions like groupBy, agg, etc.

• date_time_functions.py – Date and time functions like current_date, datediff, etc.

• joins.py – Examples of join types: inner, left, right, full.

• mathematical_functions.py – Mathematical functions like round, sqrt, log, etc.

• conversion_cast.py – Conversion and type casting using cast() and other methods.

• window_functions.py – Window functions like rank, dense_rank, lead, lag using Window spec.

## How to Run

Make sure PySpark is installed. Then run any file using:

